### Drown
<p>When we look at our hands they appear 3×10⁻⁹ seconds old. The people at the counter over there are 70×10⁻⁹ seconds old. Even though we see all of them at once we are seeing a stream of many instants; of ages.⁣ Now our senses are forming very close bonds with sources of light and sound. Brightly lit surfaces sit only a few centimetres away from our retinas, vibrating diaphragms rest on our temporal bones if not directly in our ear canals. These are the demands of so-called ‘spatial computing’: capable of sensing space itself, lenses pointed towards and away from us sense orientations and velocities of bodily gestures, durations of time spent in locations are triangulated with the tone in our voice and heart pulses read from our temples; a space that is simultaneously that of labour and of recreation, collapsed into a visual frame that wraps our eyes.</p>

<p>The spatial computer bleeds representations of our physical environments and bodies with augmented digital objects, but any leaking of light or sound may disrupt this experience. Indeed the ‘outside’ is considered a threat to the suspension of reality within the spatial computer. The term ‘immersion’ that often accompanies this experience is derived from immergere meaning to sink into a fluid; a veritable drowning must occur should the media be properly experienced. Genuine encounters with others in reality are substituted with a recording of the view that our eyes would otherwise have, even our own faces which are concurrently engulfed by a spatial computer, are substituted with an unmasked facsimile of itself. When we surface we find the world parched, our senses thirsting for the saturated sunsets and amplified sounds of forest floors we encounter when immersed in the spatial computer. Digitised drowning is replaced with the sensory barrenness of reality’s subtler hues and imperceptible sounds, and we gradually lose the ability to appreciate sensations of the real world. Our engagement with reality diminishes and real environments attempt to mimic the euphoria only experienced when fully immersed in spatial computing.</p>

<br>

### Reclaiming Tears
<p>To contemplate spatial computing we must distinguish between incidental ‘seeing’ and intentional ‘looking’. The act of seeing is the gathering of visual information during wakefulness; light enters the eyes, and signals like colour, motion and depth are processed in the visual cortex. Seeing marks the act of gleaning passively at the discretion of the beholder: how one tilts their head, how one orientates toward or away from the sun, are decisions one makes without realising, that in fact may be primordial, but decisions nonetheless that dictate what passes through our eyes.

<p>‘Looking’ by contrast, is seeing with intent; an active election to retrieve information. A focused eye implies a conscious search, or fixation on something. Looking involves cognitive processes beyond mere visual perception, engaging areas of the brain responsible for attention, memory, and decision-making. It means to take possession of the visual information streaming through our eyes.</p>

<p>The act of seeing used to be an ungovernable human act. Even in a saturated urban environment, the freedom to see remains the domain of the beholder, but in the persistent mediated reality of the spatial computer, eye movements in response to visual stimuli are linked to complex metrics that ultimately commodify sight. Movements are divided into three categories: ‘saccades’: rapid jumps to shift focus often to something new; ‘pursuit’: the smooth tracking to follow an object; and ‘vergence’: as objects converge towards—or diverge away—from us. Tear production can be measured from an emotional response or to remedy dryness from being entranced. A difference of half a millimetre is enough to register emotional stimulation, sexual arousal and demanding cognitive labour, as our iris muscles constrict and dilate our pupils. The act of seeing is not merely an instinctive act, but a domain rich in quantifiable data for eyes that are held captive.</p>

<p>Where ‘seeing’ represents the raw input stream of visual information, ‘looking’ becomes its algorithmic parsing, not unlike cinematic production, where the camera's mechanical eye performs the labour of seeing while decisions of a director, cinematographer, and editor constitute the act of looking. In the spatial computer, our eyes simultaneously perform both roles: they are the passive sensors collecting information while emitting volumes of biometric data, and they’re the active directors of our own attention. This duality creates a content vacuum: our patterns of looking inform the parameters of what we're shown, then algorithms process our visual engagement to dictate the future of what we see. Our emotional responses, be they tears, elation or otherwise, are just data points in this recursive loop, harvested to optimise content, creating an exhausted cycle of measured affect that drains the authenticity from even our most visceral reactions.</p>

<p>Outside of the spatial computer, our decision to surround ourselves with visual environments of our liking is a self-determining right. Since turning away from what we don’t want to see is impossible within the spatial computer, seeing is an unfilterable experience. Closing one’s eyes is the only way to shut off the inundation of images. In the spatial computer, we are coerced into environments not entirely of our choosing; violent visual environments sit alongside splendid ones. When immersed we must quell the act of seeing, in other words, avoid passively reacting to information we consume. Instead when we ‘look’ more, we are able to shape the course of our own quantification, and if common enough, we can dictate the algorithmic modelling of our social practices via our vision data.</p>

<p>By collectively adopting unexpected patterns of attention, lingering where we shouldn't, averting our eyes from what demands to be seen, we might corrupt the very metrics meant to capture us. Conscious collective looking poisons the dataset that feeds the algorithmic modelling of our social practices, and forms the beginning of a reclamation of our vision (tears and dilations), transforming what was meant to be passive biometric input into active signals of dissent.</p>

<br>

### Sense Throttle
<p>This unsurprisingly places more demands on the captive eye. While the outside affords us experiences of our own self-determination that we react to effortlessly, within the spatial computer we are compelled to maintain ceaseless active engagement. Our eyes, evolved for scanning horizons and reading faces, now labour without rest and everything awaits their interaction.</p>

<p>As much as seeing is coerced within the spatial computer, thankfully our physiology has its natural limits. We can only distinguish a maximum of around ten million colours of the 16 million that we are presented with; and our brain requires about 100 milliseconds to fully process what we see, creating a perpetual lag between reality and our perception of it. Even as spatial computers push faster refresh rates, our eyes and neural pathways remain bound by their evolutionary tempo, a natural throttling that no amount of technological acceleration can override. If capital could, it would present users that are ‘immersed’, with images at speeds only artificial cognition could tolerate. But seeing is already protesting. The throttling of the velocity of colour-stunted images is a shared union by which we all resist the torrential flood of digital information. We share that which is our common fallibility.</p>

<br>

### Fetish Engineerism
<p>In 1957, 29-year-old Frank Rosenblatt began work at the Cornell Aeronautical Laboratory. His goal was to create a machine that was able to recognise images. In their raw form, images contain massive amounts of data about colour, position, and relationships between pixels, and were considered were too complex for Rosenblatt’s machine to handle directly, so he resized them to fit a fixed length, converted them to grayscale, and flattened them into a single long vector. A complex image became a sequence of pixels of varying brightness, not at all resembling the original image. Rosenblatt called the machine the ‘Perceptron’. For Perceptron to understand an image, it needed to limit the information it was tasked to ‘see’ in order to comprehend it. In the same way our eyes throttle the velocity and substance of images, machines also require abstractions in order to make sense of things.</p>

<p>Likewise in object recognition, a neural network might use what are called ‘convolutional layers’ to prioritise edges, shapes, and textures to identify important features within an image. Unlike the Perceptron which flattens, discarding spatial relationships, convolutional layers process visual data without losing spatial hierarchies; they operate on a two-dimensional image by applying learnable filters, or kernels, that slide over the image. These filters compute values at each position, generating ‘feature maps’ that capture patterns like edges, textures, and shapes. Stacking multiple layers allows a neural network to learn hierarchical features, for example, in facial recognition initial layers detect lines and edges, intermediate layers identify facial components like eyes and mouths, and final layers recognise entire faces. Pooling these ‘feature maps’ downsamples the initial image while preserving salient information while enhancing computational efficiency and translation consistency.</p>

<p>Abstracting images so that they may be recognised by machines might be efficient for computational purposes, but it has profound implications for how we perceive visual information. The subject of the captive eye—the contemporary image—is now itself constrained by what machines find digestible. The image is being stripped of every skerrick of fray, boil, and aberration: everything which makes an image real. Fetish-engineerism at the expense of naturalism. Could it be that we’re rendering entire natural phenomena undocumented by choice? We have already abolished the 'twinkling' effect caused by atmospheric turbulence by using image-stacking algorithms that produce perfectly sharp images of celestial objects trillions of kilometres away.</p>

<p>A systematised fetish-engineerism of the image removes the potentials of indeterminacy at the same time. What happens when we consider indeterminacy is an expense? What happens when the captive eye is not afforded the chance to interpret the indeterminate image? Do we stifle our own intellectual and emotional selves since we no longer grapple with uncertainty? Do we forfeit a social forum to muse on the interpretations of what we don’t know?</p>

<br>

### Difficult Images
<p>The act of coinciding the captive eye with the legible image means visual perception is becoming inseparable from thinking, imagination and communication, stopping just short of an image breaching our epidermis, fed intracorporeally with seamless comprehension. Engagement ranking algorithms, for example, use feature extraction processes to analyse images for objects and scenes, then Natural Language Processing (NLP) parses textual metadata for the image. This is triangulated against multidimensional datasets encompassing user interaction metrics such as dwell time (how long a user lingers on an image) and engagement velocity (how quickly they interact with it). The algorithm assigns a relevance score to the image for individual users, ranking and curating what is seen in real-time to maximise predicted engagement metrics. This process preferentially amplifies content with high immediate interpretability and engagement potential, thereby marginalising semantically complex or ambiguous images.</p>

<p>This new culture of images is turning discerning users into audiences; images are made to take aim at targets so they remain in circulation. A user is without expectations; an audience is only observing to get a pay-off, so if the audience is stricken with an ounce of doubt about the content of the image, the image is doomed. This technical legibility-index that is organising perception ultimately neuters the audience and syphons any chance of being able to interpret indeterminacies. Together, the audience and the machine are expectant of literal classifications of content, swarmed with aestheticisation processes geared towards total legibility, which leaves unclear, ‘difficult’ images to the wayside and begins to homogenise the visual ecosystem. By contrast, the image that circulates well—the arresting palatable image—is both machine-read and consumed by a wanting audience that is chambered into a version of reality that exists only within the spatial computer.</p>

<br>

### Looking Commons
<p>If we are to reclaim control of our own sight, we need to collectively identify as a part of a continuum of looking, a kind of ommatidium: each of us a facet in a compound eye. That we may perceive less than what technology is capable of rendering is not something to mourn, but instead to savour. Further still, an acceptance of our perceptive fallibilities should be the basis upon which this renewed engagement is founded. When we synchronise our patterns of attention and withdrawal, we create a Looking Commons, corrupting the algorithmic modelling of our visual—and therefore social—consciousness. These commons are coordinated visual practices that avert our gaze from algorithmic bait; a refusal to validate content through our attention metrics to create gaps in the data streams that feed predictive models. The commons we seek isn't a space of unrelenting connectivity, but rather a shared territory of selective visibility, where the apparent weakness of our biology—our inability to process the torrent of digital information—throttles the acceleration of capital's visual regime.</p>

<p>As we surface gasping from our digital drowning, we find ourselves at a crucial junction: The very act of witnessing with eyes, has become a contested territory, where our physiological limitations emerge as vital instruments of resistance. In the spaces between pixels that cannot be parsed, it’s there that we might discover ways of relating to other species, intelligences, and new forms of empathy and connection that exist precisely because they escape algorithmic capture. Like an Aesopian duel between the might of mediated technology and our fallible eyes, we discover that our immersion is only useful to media if we can perceive it; when our pupils contract in the harsh screen light and tears well up unbidden, we're reminded of an essential truth: that even captive eyes retain their sovereign right to choose what they will not behold.</p>
